{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://mng.bz/8wdg\" target=\"_blank\">\n",
    "    <img src=\"../../Assets/Images/NewMEAPHeader.png\" alt=\"New MEAP\" style=\"width: 100%;\" />\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05[Additional] Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the necessary libraries for running this notebook along with their versions can be found in __requirements.txt__ file in the root directory of this repository\n",
    "\n",
    "You should go to the root directory and run the following command to install the libraries\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "This is the recommended method of installing the dependencies\n",
    "\n",
    "___\n",
    "Alternatively, you can run the command from this notebook too. The relative path may vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking on LangChain Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks are standardized datasets and their evaluation metrics used to measure the performance of RAG systems. Benchmarks provide a common ground for comparing different RAG approaches. Benchmarks ensure consistency across the evaluations by considering a fixed set of tasks and their evaluation criteria. For example, HotpotQA focusses on multi-hop reasoning and retrieval capabilities using metrics like Exact Match and F1 scores. Benchmarks are used to establish a baseline for performance and identify strengths/weaknesses is specific tasks or domains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides its own benchmarking using the langchain-benchmarks library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You will need an __OpenAI API Key__ which can be obtained from [OpenAI](https://platform.openai.com/api-keys) to reuse the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You will also need a __LangSmith API key__. You can make a free account on [LangChain website](http://smith.langchain.com). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  [Option 1] Creating a .env file for storing the API key and using it # Recommended\n",
    "\n",
    "Install the __dotenv__ library\n",
    "\n",
    "_The dotenv library is a popular tool used in various programming languages, including Python and Node.js, to manage environment variables in development and deployment environments. It allows developers to load environment variables from a .env file into their application's environment._\n",
    "\n",
    "- Create a file named .env in the root directory of their project.\n",
    "- Inside the .env file, then define environment variables in the format VARIABLE_NAME=value. \n",
    "\n",
    "e.g.\n",
    "\n",
    "OPENAI_API_KEY=YOUR API KEY\n",
    "\n",
    "LANGCHAIN_API_KEY=YOUR API KEY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: .env file found with some environment variables\n"
     ]
    }
   ],
   "source": [
    "del os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Success: .env file found with some environment variables\")\n",
    "else:\n",
    "    print(\"Caution: No environment variables found. Please create .env file in the root directory or add environment variables in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Option 2] Alternatively, you can set the API key in code. \n",
    "However, this is not recommended since it can leave your key exposed for potential misuse. Uncomment the cell below to use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-******\" #Imp : Replace with an OpenAI API Key\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"lsv2-******\" #Imp : Replace with an OpenAI API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will have to provide the langsmith endpoint to view the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a unique run_id will help us in tracking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "run_uid = uuid.uuid4().hex[:6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides multiple datasets for benchmarking via its registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry\n",
    "registry = registry.filter(Type=\"RetrievalTask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the datasets for Retrieval Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Name                   </th><th>Type         </th><th>Dataset ID                                                                                                                                                 </th><th>Description  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>LangChain Docs Q&A     </td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
       "\n",
       "The environment provides the documents and the retriever information.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n",
       "<tr><td>Semi-structured Reports</td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d\" target=\"_blank\" rel=\"noopener\">c47d9617-ab99-4d6e-a6e6-92b8daf85a7d</a></td><td>Questions and answers based on PDFs containing tables and charts.\n",
       "\n",
       "The task provides the raw documents as well as factory methods to easily index them\n",
       "and create a retriever.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n",
       "<tr><td>Multi-modal slide decks</td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/40afc8e7-9d7e-44ed-8971-2cae1eb59731/d\" target=\"_blank\" rel=\"noopener\">40afc8e7-9d7e-44ed-8971-2cae1eb59731</a></td><td>This public dataset is a work-in-progress and will be extended over time.\n",
       "        \n",
       "Questions and answers based on slide decks containing visual tables and charts.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Registry(tasks=[RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_cached_docs at 0x131cd6fc0>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x131ce4a40>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x131ce4ae0>, 'hyde': <function _chroma_hyde_retriever_factory at 0x131ce4b80>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x1308376a0>}), RetrievalTask(name='Semi-structured Reports', dataset_id='https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d', description=\"Questions and answers based on PDFs containing tables and charts.\\n\\nThe task provides the raw documents as well as factory methods to easily index them\\nand create a retriever.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_docs at 0x131ce5580>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x131ce5620>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x131ce56c0>, 'hyde': <function _chroma_hyde_retriever_factory at 0x131ce5760>}, architecture_factories={}), RetrievalTask(name='Multi-modal slide decks', dataset_id='https://smith.langchain.com/public/40afc8e7-9d7e-44ed-8971-2cae1eb59731/d', description='This public dataset is a work-in-progress and will be extended over time.\\n        \\nQuestions and answers based on slide decks containing visual tables and charts.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\n', get_docs={}, retriever_factories={}, architecture_factories={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the LangChain Docs Q&A here \n",
    "\n",
    "It is a snapshot of the LangChain python documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_docs = registry[\"LangChain Docs Q&A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will have to clone the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset LangChain Docs Q&A already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/73c092fe-78e5-454c-b060-59c1c6abf51a/datasets/8ac24ee3-60c9-4472-855c-5395fbe6234f.\n"
     ]
    }
   ],
   "source": [
    "clone_public_dataset(langchain_docs.dataset_id, dataset_name=langchain_docs.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visit the link above to view the dataset. Below is a snapshot of the data on LangSmith\n",
    "\n",
    "<img src=\"../../Assets/Images/5.1 1.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'changefreq': 'weekly', 'description': 'Example code for building applications with LangChain, with an emphasis on more applied and end-to-end examples than contained in the main documentation.', 'language': 'en', 'loc': 'https://python.langchain.com/cookbook', 'priority': '0.5', 'source': 'https://python.langchain.com/cookbook', 'title': 'LangChain cookbook | 🦜️🔗 Langchain'}, page_content=\"LangChain cookbook | 🦜️🔗 Langchain\\n\\n[Skip to main content](#docusaurus_skipToContent_fallback)# LangChain cookbook\\n\\nExample code for building applications with LangChain, with an emphasis on more applied and end-to-end examples than contained in the [main documentation](https://python.langchain.com).\\n\\n| Notebook | Description |\\n| ---- | ---- |\\n| LLaMA2_sql_chat.ipynb | Build a chat application that interacts with a SQL database using an open source llm (llama2), specifically demonstrated on an SQLite database containing rosters. |\\n| Semi_Structured_RAG.ipynb | Perform retrieval-augmented generation (rag) on documents with semi-structured data, including text and tables, using unstructured for parsing, multi-vector retriever for storing, and lcel for implementing chains. |\\n| Semi_structured_and_multi_moda... | Perform retrieval-augmented generation (rag) on documents with semi-structured data and images, using unstructured for parsing, multi-vector retriever for storage and retrieval, and lcel for implementing chains. |\\n| Semi_structured_multi_modal_RA... | Perform retrieval-augmented generation (rag) on documents with semi-structured data and images, using various tools and methods such as unstructured for parsing, multi-vector retriever for storing, lcel for implementing chains, and open source language models like llama2, llava, and gpt4all. |\\n| analyze_document.ipynb | Analyze a single long document. |\\n| autogpt/autogpt.ipynb | Implement autogpt, a language model, with langchain primitives such as llms, prompttemplates, vectorstores, embeddings, and tools. |\\n| autogpt/marathon_times.ipynb | Implement autogpt for finding winning marathon times. |\\n| baby_agi.ipynb | Implement babyagi, an ai agent that can generate and execute tasks based on a given objective, with the flexibility to swap out specific vectorstores/model providers. |\\n| baby_agi_with_agent.ipynb | Swap out the execution chain in the babyagi notebook with an agent that has access to tools, aiming to obtain more reliable information. |\\n| camel_role_playing.ipynb | Implement the camel framework for creating autonomous cooperative agents in large-scale language models, using role-playing and inception prompting to guide chat agents towards task completion. |\\n| causalprogram_aided_language... | Implement the causal program-aided language (cpal) chain, which improves upon the program-aided language (pal) by incorporating causal structure to prevent hallucination in language models, particularly when dealing with complex narratives and math problems with nested dependencies. |\\n| code-analysis-deeplake.ipynb | Analyze its own code base with the help of gpt and activeloop's deep lake. |\\n| custom_agent_with_plugin_retri... | Build a custom agent that can interact with ai plugins by retrieving tools and creating natural language wrappers around openapi endpoints. |\\n| custom_agent_with_plugin_retri... | Build a custom agent with plugin retrieval functionality, utilizing ai plugins from theplugnplaidirectory. |\\n| databricks_sql_db.ipynb | Connect to databricks runtimes and databricks sql. |\\n| deeplakesemantic_search_over... | Perform semantic search and question-answering over a group chat using activeloop's deep lake with gpt4. |\\n| elasticsearch_db_qa.ipynb | Interact with elasticsearch analytics databases in natural language and build search queries via the elasticsearch dsl API. |\\n| extraction_openai_tools.ipynb | Structured Data Extraction with OpenAI Tools |\\n| forward_looking_retrieval_augm... | Implement the forward-looking active retrieval augmented generation (flare) method, which generates answers to questions, identifies uncertain tokens, generates hypothetical questions based on these tokens, and retrieves relevant documents to continue generating the answer. |\\n| generativeagents_interactive... | Implement a generative agent that simulates human behavior, based on a research paper, using a time-weighted memory object backed by a langchain retriever. |\\n| gymnasium_agent_simulation.ipynb | Create a simple agent-environment interaction loop in simulated environments like text-based games with gymnasium. |\\n| hugginggpt.ipynb | Implement hugginggpt, a system that connects language models like chatgpt with the machine learning community via hugging face. |\\n| hypothetical_document_embeddin... | Improve document indexing with hypothetical document embeddings (hyde), an embedding technique that generates and embeds hypothetical answers to queries. |\\n| learned_prompt_optimization.ipynb | Automatically enhance language model prompts by injecting specific terms using reinforcement learning, which can be used to personalize responses based on user preferences. |\\n| llm_bash.ipynb | Perform simple filesystem commands using language learning models (llms) and a bash process. |\\n| llm_checker.ipynb | Create a self-checking chain using the llmcheckerchain function. |\\n| llm_math.ipynb | Solve complex word math problems using language models and python repls. |\\n| llm_summarization_checker.ipynb | Check the accuracy of text summaries, with the option to run the checker multiple times for improved results. |\\n| llm_symbolic_math.ipynb | Solve algebraic equations with the help of llms (language learning models) and sympy, a python library for symbolic mathematics. |\\n| meta_prompt.ipynb | Implement the meta-prompt concept, which is a method for building self-improving agents that reflect on their own performance and modify their instructions accordingly. |\\n| multi_modal_output_agent.ipynb | Generate multi-modal outputs, specifically images and text. |\\n| multi_player_dnd.ipynb | Simulate multi-player dungeons & dragons games, with a custom function determining the speaking schedule of the agents. |\\n| multiagent_authoritarian.ipynb | Implement a multi-agent simulation where a privileged agent controls the conversation, including deciding who speaks and when the conversation ends, in the context of a simulated news network. |\\n| multiagent_bidding.ipynb | Implement a multi-agent simulation where agents bid to speak, with the highest bidder speaking next, demonstrated through a fictitious presidential debate example. |\\n| myscale_vector_sql.ipynb | Access and interact with the myscale integrated vector database, which can enhance the performance of language model (llm) applications. |\\n| openai_functions_retrieval_qa.... | Structure response output in a question-answering system by incorporating openai functions into a retrieval pipeline. |\\n| openai_v1_cookbook.ipynb | Explore new functionality released alongside the V1 release of the OpenAI Python library. |\\n| petting_zoo.ipynb | Create multi-agent simulations with simulated environments using the petting zoo library. |\\n| plan_and_execute_agent.ipynb | Create plan-and-execute agents that accomplish objectives by planning tasks with a language model (llm) and executing them with a separate agent. |\\n| press_releases.ipynb | Retrieve and query company press release data powered byKay.ai. |\\n| program_aided_language_model.i... | Implement program-aided language models as described in the provided research paper. |\\n| qa_citations.ipynb | Different ways to get a model to cite its sources. |\\n| retrieval_in_sql.ipynb | Perform retrieval-augmented-generation (rag) on a PostgreSQL database using pgvector. |\\n| sales_agent_with_context.ipynb | Implement a context-aware ai sales agent, salesgpt, that can have natural sales conversations, interact with other systems, and use a product knowledge base to discuss a company's offerings. |\\n| self_query_hotel_search.ipynb | Build a hotel room search feature with self-querying retrieval, using a specific hotel recommendation dataset. |\\n| smart_llm.ipynb | Implement a smartllmchain, a self-critique chain that generates multiple output proposals, critiques them to find the best one, and then improves upon it to produce a final output. |\\n| tree_of_thought.ipynb | Query a large language model using the tree of thought technique. |\\n| twitter-the-algorithm-analysis... | Analyze the source code of the Twitter algorithm with the help of gpt4 and activeloop's deep lake. |\\n| two_agent_debate_tools.ipynb | Simulate multi-agent dialogues where the agents can utilize various tools. |\\n| two_player_dnd.ipynb | Simulate a two-player dungeons & dragons game, where a dialogue simulator class is used to coordinate the dialogue between the protagonist and the dungeon master. |\\n| wikibase_agent.ipynb | Create a simple wikibase agent that utilizes sparql generation, with testing done onhttp://wikidata.org. |\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = list(langchain_docs.get_docs())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing LangChain Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "db=FAISS.from_documents(docs,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting db as retriever in LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Augmentation prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"human\", \n",
    "    \"Given the context below answer the question.\"\n",
    "    \"\\nQuestion: {question}\\n\"\n",
    "    \"\\nContext : {context}\\n\"\n",
    "    \"\\nRemember to answer only based on the context provided and not from any other source.\\n\"\n",
    "    \"\\nIf the question cannot be answered based on the provided context, say I don’t know.\\n\"\n",
    "    ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Generation Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating function for extracting text from retrieved document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs) -> str:\n",
    "    \n",
    "    return docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "chain=RunnableAssign(\n",
    "        {\n",
    "            \"context\": (itemgetter(\"question\") | retriever| format_docs)\n",
    "        }\n",
    ")|prompt|llm|StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoking RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LC expression language, or LangChain Expression Language (LCEL), is a declarative way to compose chains together in LangChain. It supports the creation and deployment of chains with no code changes, enabling functionality from simple prompt + LLM chains to more complex chains with hundreds of steps. LCEL includes features such as streaming support, async support, optimized parallel execution, retries and fallbacks, access to intermediate results, input and output schemas, and integration with LangSmith for tracing and debugging, as well as LangServe for deployment.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What's LC expression language?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.client import Client\n",
    "#from langchain_benchmarks.rag import get_eval_config\n",
    "from evaluators import get_eval_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above that we are using the __get_eval_config__ function from the local code repo. This is because of a bug in the LangChain repo. We can go back to using the function from langchain_benchmarks.rag once the bug is resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'SGRAG BENCH 96ca3b' at:\n",
      "https://smith.langchain.com/o/73c092fe-78e5-454c-b060-59c1c6abf51a/datasets/8ac24ee3-60c9-4472-855c-5395fbe6234f/compare?selectedSessions=24818c8d-9f95-435f-a13a-72834650b59f\n",
      "\n",
      "View all tests for Dataset LangChain Docs Q&A at:\n",
      "https://smith.langchain.com/o/73c092fe-78e5-454c-b060-59c1c6abf51a/datasets/8ac24ee3-60c9-4472-855c-5395fbe6234f\n",
      "[>                                                 ] 0/86\n",
      "d\n",
      "\n",
      "[>                                                 ] 1/86\n",
      "d\n",
      "\n",
      "[>                                                 ] 2/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[->                                                ] 4/86\n",
      "d\n",
      "\n",
      "[-->                                               ] 5/86\n",
      "d\n",
      "\n",
      "[-->                                               ] 6/86\n",
      "d\n",
      "\n",
      "[--->                                              ] 7/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[---->                                             ] 9/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[----->                                            ] 11/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[------->                                          ] 14/86\n",
      "d\n",
      "\n",
      "[-------->                                         ] 16/86\n",
      "d\n",
      "\n",
      "[--------->                                        ] 17/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[---------->                                       ] 19/86\n",
      "d\n",
      "\n",
      "[----------->                                      ] 20/86\n",
      "d\n",
      "\n",
      "[----------->                                      ] 21/86\n",
      "d\n",
      "\n",
      "[------------>                                     ] 22/86\n",
      "d\n",
      "\n",
      "[------------>                                     ] 23/86\n",
      "d\n",
      "\n",
      "[------------->                                    ] 24/86\n",
      "d\n",
      "\n",
      "[-------------->                                   ] 25/86\n",
      "d\n",
      "\n",
      "[-------------->                                   ] 26/86\n",
      "d\n",
      "\n",
      "[--------------->                                  ] 27/86\n",
      "d\n",
      "\n",
      "[--------------->                                  ] 28/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[---------------->                                 ] 30/86\n",
      "d\n",
      "\n",
      "[----------------->                                ] 31/86\n",
      "d\n",
      "\n",
      "[------------------>                               ] 32/86\n",
      "d\n",
      "\n",
      "[------------------>                               ] 33/86\n",
      "d\n",
      "\n",
      "[------------------->                              ] 34/86\n",
      "d\n",
      "\n",
      "[------------------->                              ] 35/86\n",
      "d\n",
      "\n",
      "[-------------------->                             ] 36/86\n",
      "d\n",
      "\n",
      "[--------------------->                            ] 37/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[---------------------->                           ] 40/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[----------------------->                          ] 42/86\n",
      "d\n",
      "\n",
      "[------------------------>                         ] 43/86\n",
      "d\n",
      "\n",
      "[------------------------->                        ] 44/86\n",
      "d\n",
      "\n",
      "[------------------------->                        ] 45/86\n",
      "d\n",
      "\n",
      "[-------------------------->                       ] 46/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[--------------------------->                      ] 48/86\n",
      "d\n",
      "\n",
      "[--------------------------->                      ] 49/86\n",
      "d\n",
      "\n",
      "[---------------------------->                     ] 50/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[----------------------------->                    ] 52/86\n",
      "d\n",
      "\n",
      "[------------------------------>                   ] 53/86\n",
      "d\n",
      "\n",
      "[------------------------------>                   ] 54/86\n",
      "d\n",
      "\n",
      "[------------------------------->                  ] 55/86\n",
      "d\n",
      "\n",
      "[-------------------------------->                 ] 56/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[--------------------------------->                ] 58/86\n",
      "d\n",
      "\n",
      "[--------------------------------->                ] 59/86\n",
      "d\n",
      "\n",
      "[---------------------------------->               ] 60/86\n",
      "d\n",
      "\n",
      "[---------------------------------->               ] 61/86\n",
      "d\n",
      "\n",
      "[----------------------------------->              ] 62/86\n",
      "d\n",
      "\n",
      "[------------------------------------>             ] 63/86\n",
      "d\n",
      "\n",
      "[------------------------------------>             ] 64/86\n",
      "d\n",
      "\n",
      "[------------------------------------->            ] 65/86\n",
      "d\n",
      "\n",
      "[------------------------------------->            ] 66/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[--------------------------------------->          ] 68/86\n",
      "d\n",
      "\n",
      "[--------------------------------------->          ] 69/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[----------------------------------------->        ] 72/86\n",
      "d\n",
      "\n",
      "[----------------------------------------->        ] 73/86\n",
      "d\n",
      "\n",
      "[------------------------------------------>       ] 74/86\n",
      "d\n",
      "\n",
      "[------------------------------------------->      ] 75/86\n",
      "d\n",
      "\n",
      "[------------------------------------------->      ] 76/86\n",
      "d\n",
      "\n",
      "[-------------------------------------------->     ] 77/86\n",
      "d\n",
      "\n",
      "[-------------------------------------------->     ] 78/86\n",
      "d\n",
      "\n",
      "[--------------------------------------------->    ] 79/86\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "\n",
      "[---------------------------------------------->   ] 81/86\n",
      "d\n",
      "\n",
      "[----------------------------------------------->  ] 82/86\n",
      "d\n",
      "\n",
      "[----------------------------------------------->  ] 83/86\n",
      "d\n",
      "\n",
      "[------------------------------------------------> ] 84/86\n",
      "d\n",
      "\n",
      "[------------------------------------------------> ] 85/86\n",
      "d\n",
      "\n",
      "[------------------------------------------------->] 86/86"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.score_string:accuracy</th>\n",
       "      <th>feedback.embedding_cosine_distance</th>\n",
       "      <th>feedback.faithfulness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7c97bc6e-fd00-4e37-b0c5-a751a1977776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.539535</td>\n",
       "      <td>0.141360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.454959</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.352563</td>\n",
       "      <td>0.087092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.734309</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962486</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.079750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.821399</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.110859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.600614</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.189536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.139267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.358477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.881710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.score_string:accuracy  feedback.embedding_cosine_distance  \\\n",
       "count                        86.000000                           86.000000   \n",
       "unique                             NaN                                 NaN   \n",
       "top                                NaN                                 NaN   \n",
       "freq                               NaN                                 NaN   \n",
       "mean                          0.539535                            0.141360   \n",
       "std                           0.352563                            0.087092   \n",
       "min                           0.100000                            0.023760   \n",
       "25%                           0.100000                            0.079750   \n",
       "50%                           0.500000                            0.110859   \n",
       "75%                           0.975000                            0.189536   \n",
       "max                           1.000000                            0.358477   \n",
       "\n",
       "       feedback.faithfulness error  execution_time  \\\n",
       "count                      0     0       86.000000   \n",
       "unique                     0     0             NaN   \n",
       "top                      NaN   NaN             NaN   \n",
       "freq                     NaN   NaN             NaN   \n",
       "mean                     NaN   NaN        3.454959   \n",
       "std                      NaN   NaN        2.734309   \n",
       "min                      NaN   NaN        0.962486   \n",
       "25%                      NaN   NaN        1.821399   \n",
       "50%                      NaN   NaN        2.600614   \n",
       "75%                      NaN   NaN        4.139267   \n",
       "max                      NaN   NaN       19.881710   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     86  \n",
       "unique                                    86  \n",
       "top     7c97bc6e-fd00-4e37-b0c5-a751a1977776  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = Client()\n",
    "RAG_EVALUATION = get_eval_config()\n",
    "\n",
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    project_name=f\"SGRAG BENCH {run_uid}\",\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.score_string:accuracy</th>\n",
       "      <th>feedback.embedding_cosine_distance</th>\n",
       "      <th>feedback.faithfulness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7c97bc6e-fd00-4e37-b0c5-a751a1977776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.539535</td>\n",
       "      <td>0.141360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.454959</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.352563</td>\n",
       "      <td>0.087092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.734309</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962486</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.079750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.821399</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.110859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.600614</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.189536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.139267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.358477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.881710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.score_string:accuracy  feedback.embedding_cosine_distance  \\\n",
       "count                        86.000000                           86.000000   \n",
       "unique                             NaN                                 NaN   \n",
       "top                                NaN                                 NaN   \n",
       "freq                               NaN                                 NaN   \n",
       "mean                          0.539535                            0.141360   \n",
       "std                           0.352563                            0.087092   \n",
       "min                           0.100000                            0.023760   \n",
       "25%                           0.100000                            0.079750   \n",
       "50%                           0.500000                            0.110859   \n",
       "75%                           0.975000                            0.189536   \n",
       "max                           1.000000                            0.358477   \n",
       "\n",
       "       feedback.faithfulness error  execution_time  \\\n",
       "count                      0     0       86.000000   \n",
       "unique                     0     0             NaN   \n",
       "top                      NaN   NaN             NaN   \n",
       "freq                     NaN   NaN             NaN   \n",
       "mean                     NaN   NaN        3.454959   \n",
       "std                      NaN   NaN        2.734309   \n",
       "min                      NaN   NaN        0.962486   \n",
       "25%                      NaN   NaN        1.821399   \n",
       "50%                      NaN   NaN        2.600614   \n",
       "75%                      NaN   NaN        4.139267   \n",
       "max                      NaN   NaN       19.881710   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     86  \n",
       "unique                                    86  \n",
       "top     7c97bc6e-fd00-4e37-b0c5-a751a1977776  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../Assets/Images/profile_s.png\" width=100> \n",
    "\n",
    "Hi! I'm Abhinav! I am an entrepreneur and Vice President of Artificial Intelligence at Yarnit. I have spent over 15 years consulting and leadership roles in data science, machine learning and AI. My current focus is in the applied Generative AI domain focussing on solving enterprise needs through contextual intelligence. I'm passionate about AI advancements constantly exploring emerging technologies to push the boundaries and create positive impacts in the world. Let’s build the future, together!\n",
    "\n",
    "[If you haven't already, please subscribe to the MEAP of A Simple Guide to Retrieval Augmented Generation here](https://mng.bz/8wdg)\n",
    "\n",
    "<a href=\"https://mng.bz/8wdg\" target=\"_blank\">\n",
    "    <img src=\"../../Assets/Images/NewMEAPFooter.png\" alt=\"New MEAP\" style=\"width: 100%;\" />\n",
    "</a>\n",
    "\n",
    "#### If you'd like to chat, I'd be very happy to connect\n",
    "\n",
    "[![GitHub followers](https://img.shields.io/badge/Github-000000?style=for-the-badge&logo=github&logoColor=black&color=orange)](https://github.com/abhinav-kimothi)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-000000?style=for-the-badge&logo=linkedin&logoColor=orange&color=black)](https://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=abhinav-kimothi)\n",
    "[![Medium](https://img.shields.io/badge/Medium-000000?style=for-the-badge&logo=medium&logoColor=black&color=orange)](https://medium.com/@abhinavkimothi)\n",
    "[![Insta](https://img.shields.io/badge/Instagram-000000?style=for-the-badge&logo=instagram&logoColor=orange&color=black)](https://www.instagram.com/akaiworks/)\n",
    "[![Mail](https://img.shields.io/badge/email-000000?style=for-the-badge&logo=gmail&logoColor=black&color=orange)](mailto:abhinav.kimothi.ds@gmail.com)\n",
    "[![X](https://img.shields.io/badge/Follow-000000?style=for-the-badge&logo=X&logoColor=orange&color=black)](https://twitter.com/abhinav_kimothi)\n",
    "[![Linktree](https://img.shields.io/badge/Linktree-000000?style=for-the-badge&logo=linktree&logoColor=black&color=orange)](https://linktr.ee/abhinavkimothi)\n",
    "[![Gumroad](https://img.shields.io/badge/Gumroad-000000?style=for-the-badge&logo=gumroad&logoColor=orange&color=black)](https://abhinavkimothi.gumroad.com/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
